{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Alternative Model (Training)\n",
    "\n",
    "I've found WaveRNN quite slow to train so here's an alternative that utilises the optimised rnn kernels in Pytorch. The model below is much much faster to train, it will converge in 48hrs when training on 22.5kHz samples (or 24hrs using 16kHz samples) on a single GTX1080. It also works quite well with predicted GTA features. \n",
    "\n",
    "The model is simply two residual GRUs in sequence and then three dense layers with a 512 softmax output. This is supplemented with an upsampling network.\n",
    "\n",
    "Since the Pytorch rnn kernels are 'closed', the options for conditioning sites are greatly reduced. Here's the strategy I went with given that restriction:  \n",
    "\n",
    "1 - Upsampling: Nearest neighbour upsampling followed by 2d convolutions with 'horizontal' kernels to interpolate. Split up into two or three layers depending on the stft hop length.\n",
    "\n",
    "2 - A 1d resnet with a 5 wide conv input and 1x1 res blocks. Not sure if this is necessary, but the thinking behind it is: the upsampled features give a local view of the conditioning - why not supplement that with a much wider view of conditioning features, including a peek at the future. One thing to note is that the resnet is computed only once and in parallel, so it shouldn't slow down training/generation much. \n",
    "\n",
    "There's a good chance this model needs regularisation since it overfits a little, so for now train it to ~500k steps for best results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cd /home/erogol/Projects/WaveRNN/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import math, pickle, os\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch.autograd import Variable \n",
    "from torch import optim\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from utils.display import *\n",
    "from utils.audio import AudioProcessor\n",
    "from utils.generic_utils import load_config\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "torch.backends.cudnn.benchmark=False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config_path = '../TTS/config.json'\n",
    "\n",
    "CONFIG = load_config(config_path)\n",
    "ap = AudioProcessor(CONFIG.sample_rate, CONFIG.num_mels, CONFIG.min_level_db,\n",
    "                    CONFIG.frame_shift_ms, CONFIG.frame_length_ms,\n",
    "                    CONFIG.ref_level_db, CONFIG.num_freq, CONFIG.power, CONFIG.preemphasis,\n",
    "                    griffin_lim_iters=50)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bits = 9\n",
    "\n",
    "seq_len = ap.hop_length * 5\n",
    "seq_len\n",
    "\n",
    "notebook_name = 'wavernn_ljspeech'\n",
    "\n",
    "%mkdir -p 'model_checkpoints/'\n",
    "\n",
    "MODEL_PATH = f'model_checkpoints/{notebook_name}.pyt'\n",
    "DATA_PATH = f'data/{notebook_name}/'\n",
    "STEP_PATH = f'model_checkpoints/{notebook_name}_step.npy'\n",
    "GEN_PATH = f'model_outputs/{notebook_name}/'\n",
    "%mkdir -p $GEN_PATH"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(f'{DATA_PATH}dataset_ids.pkl', 'rb') as f:\n",
    "    dataset_ids = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_ids = dataset_ids[-50:]\n",
    "dataset_ids = dataset_ids[:-50]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "class AudiobookDataset(Dataset):\n",
    "    def __init__(self, ids, path):\n",
    "        self.path = path\n",
    "        self.metadata = ids\n",
    "        \n",
    "    def __getitem__(self, index):\n",
    "        file = self.metadata[index]\n",
    "        m = np.load(f'{self.path}mel/{file}.npy')\n",
    "        x = np.load(f'{self.path}quant/{file}.npy')\n",
    "        return m, x\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.metadata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def collate(batch) :\n",
    "    \n",
    "    pad = 2\n",
    "    mel_win = seq_len // ap.hop_length + 2 * pad\n",
    "    max_offsets = [x[0].shape[-1] - (mel_win + 2 * pad) for x in batch]\n",
    "    mel_offsets = [np.random.randint(0, offset) for offset in max_offsets]\n",
    "    sig_offsets = [(offset + pad) * ap.hop_length for offset in mel_offsets]\n",
    "    \n",
    "    mels = [x[0][:, mel_offsets[i]:mel_offsets[i] + mel_win] \\\n",
    "            for i, x in enumerate(batch)]\n",
    "    \n",
    "    coarse = [x[1][sig_offsets[i]:sig_offsets[i] + seq_len + 1] \\\n",
    "              for i, x in enumerate(batch)]\n",
    "    \n",
    "    mels = np.stack(mels).astype(np.float32)\n",
    "    coarse = np.stack(coarse).astype(np.int64)\n",
    "    \n",
    "    mels = torch.FloatTensor(mels)\n",
    "    coarse = torch.LongTensor(coarse)\n",
    "    \n",
    "    x_input = 2 * coarse[:, :seq_len].float() / (2**bits - 1.) - 1.\n",
    "    \n",
    "    y_coarse = coarse[:, 1:]\n",
    "    \n",
    "    return x_input, mels, y_coarse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = AudiobookDataset(dataset_ids, DATA_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_loader = DataLoader(dataset, collate_fn=collate, batch_size=32, \n",
    "                         num_workers=0, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x, m, y = next(iter(data_loader))\n",
    "x.shape, m.shape, y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot(x.numpy()[0]) \n",
    "plot(y.numpy()[0])\n",
    "plot_spec(m.numpy()[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define Model Classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResBlock(nn.Module) :\n",
    "    def __init__(self, dims) :\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv1d(dims, dims, kernel_size=1, bias=False)\n",
    "        self.conv2 = nn.Conv1d(dims, dims, kernel_size=1, bias=False)\n",
    "        self.batch_norm1 = nn.BatchNorm1d(dims)\n",
    "        self.batch_norm2 = nn.BatchNorm1d(dims)\n",
    "        \n",
    "    def forward(self, x) :\n",
    "        residual = x\n",
    "        x = self.conv1(x)\n",
    "        x = self.batch_norm1(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.conv2(x)\n",
    "        x = self.batch_norm2(x)\n",
    "        return x + residual"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MelResNet(nn.Module) :\n",
    "    def __init__(self, res_blocks, in_dims, compute_dims, res_out_dims) :\n",
    "        super().__init__()\n",
    "        self.conv_in = nn.Conv1d(in_dims, compute_dims, kernel_size=5, bias=False)\n",
    "        self.batch_norm = nn.BatchNorm1d(compute_dims)\n",
    "        self.layers = nn.ModuleList()\n",
    "        for i in range(res_blocks) :\n",
    "            self.layers.append(ResBlock(compute_dims))\n",
    "        self.conv_out = nn.Conv1d(compute_dims, res_out_dims, kernel_size=1)\n",
    "        \n",
    "    def forward(self, x) :\n",
    "        x = self.conv_in(x)\n",
    "        x = self.batch_norm(x)\n",
    "        x = F.relu(x)\n",
    "        for f in self.layers : x = f(x)\n",
    "        x = self.conv_out(x)\n",
    "        return x        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Stretch2d(nn.Module) :\n",
    "    def __init__(self, x_scale, y_scale) :\n",
    "        super().__init__()\n",
    "        self.x_scale = x_scale\n",
    "        self.y_scale = y_scale\n",
    "        \n",
    "    def forward(self, x) :\n",
    "        b, c, h, w = x.size()\n",
    "        x = x.unsqueeze(-1).unsqueeze(3)\n",
    "        x = x.repeat(1, 1, 1, self.y_scale, 1, self.x_scale)\n",
    "        return x.view(b, c, h * self.y_scale, w * self.x_scale)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class UpsampleNetwork(nn.Module) :\n",
    "    def __init__(self, feat_dims, upsample_scales, compute_dims, \n",
    "                 res_blocks, res_out_dims, pad) :\n",
    "        super().__init__()\n",
    "        total_scale = np.cumproduct(upsample_scales)[-1]\n",
    "        self.indent = pad * total_scale\n",
    "        self.resnet = MelResNet(res_blocks, feat_dims, compute_dims, res_out_dims)\n",
    "        self.resnet_stretch = Stretch2d(total_scale, 1)\n",
    "        self.up_layers = nn.ModuleList()\n",
    "        for scale in upsample_scales :\n",
    "            k_size = (1, scale * 2 + 1)\n",
    "            padding = (0, scale)\n",
    "            stretch = Stretch2d(scale, 1)\n",
    "            conv = nn.Conv2d(1, 1, kernel_size=k_size, padding=padding, bias=False)\n",
    "            conv.weight.data.fill_(1. / k_size[1])\n",
    "            self.up_layers.append(stretch)\n",
    "            self.up_layers.append(conv)\n",
    "    \n",
    "    def forward(self, m) :\n",
    "        aux = self.resnet(m).unsqueeze(1)\n",
    "        aux = self.resnet_stretch(aux)\n",
    "        aux = aux.squeeze(1)\n",
    "        m = m.unsqueeze(1)\n",
    "        for f in self.up_layers : m = f(m)\n",
    "        m = m.squeeze(1)[:, :, self.indent:-self.indent]\n",
    "        return m.transpose(1, 2), aux.transpose(1, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     27
    ]
   },
   "outputs": [],
   "source": [
    "class Model(nn.Module) :\n",
    "    def __init__(self, rnn_dims, fc_dims, bits, pad, upsample_factors,\n",
    "                 feat_dims, compute_dims, res_out_dims, res_blocks):\n",
    "        super().__init__()\n",
    "        self.n_classes = 2**bits\n",
    "        self.rnn_dims = rnn_dims\n",
    "        self.aux_dims = res_out_dims // 4\n",
    "        self.upsample = UpsampleNetwork(feat_dims, upsample_factors, compute_dims, \n",
    "                                        res_blocks, res_out_dims, pad)\n",
    "        self.I = nn.Linear(feat_dims + self.aux_dims + 1, rnn_dims)\n",
    "        self.rnn1 = nn.GRU(rnn_dims, rnn_dims, batch_first=True)\n",
    "        self.rnn2 = nn.GRU(rnn_dims + self.aux_dims, rnn_dims, batch_first=True)\n",
    "        self.fc1 = nn.Linear(rnn_dims + self.aux_dims, fc_dims)\n",
    "        self.fc2 = nn.Linear(fc_dims + self.aux_dims, fc_dims)\n",
    "        self.fc3 = nn.Linear(fc_dims, self.n_classes)\n",
    "        num_params(self)\n",
    "    \n",
    "    def forward(self, x, mels) :\n",
    "        bsize = x.size(0)\n",
    "        h1 = torch.zeros(1, bsize, self.rnn_dims).cuda()\n",
    "        h2 = torch.zeros(1, bsize, self.rnn_dims).cuda()\n",
    "        mels, aux = self.upsample(mels)\n",
    "        \n",
    "        aux_idx = [self.aux_dims * i for i in range(5)]\n",
    "        a1 = aux[:, :, aux_idx[0]:aux_idx[1]]\n",
    "        a2 = aux[:, :, aux_idx[1]:aux_idx[2]]\n",
    "        a3 = aux[:, :, aux_idx[2]:aux_idx[3]]\n",
    "        a4 = aux[:, :, aux_idx[3]:aux_idx[4]]\n",
    "        \n",
    "        x = torch.cat([x.unsqueeze(-1), mels, a1], dim=2)\n",
    "        x = self.I(x)\n",
    "        res = x\n",
    "        x, _ = self.rnn1(x, h1)\n",
    "        \n",
    "        x = x + res\n",
    "        res = x\n",
    "        x = torch.cat([x, a2], dim=2)\n",
    "        x, _ = self.rnn2(x, h2)\n",
    "        \n",
    "        x = x + res\n",
    "        x = torch.cat([x, a3], dim=2)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        \n",
    "        x = torch.cat([x, a4], dim=2)\n",
    "        x = F.relu(self.fc2(x))\n",
    "        return F.log_softmax(self.fc3(x), dim=-1)\n",
    "    \n",
    "    def preview_upsampling(self, mels) :\n",
    "        mels, aux = self.upsample(mels)\n",
    "        return mels, aux\n",
    "    \n",
    "    def generate(self, mels) :\n",
    "        self.eval()\n",
    "        output = []\n",
    "        rnn1 = self.get_gru_cell(self.rnn1)\n",
    "        rnn2 = self.get_gru_cell(self.rnn2)\n",
    "        \n",
    "        with torch.no_grad() :\n",
    "            start = time.time()\n",
    "            x = torch.zeros(1, 1).cuda()\n",
    "            h1 = torch.zeros(1, self.rnn_dims).cuda()\n",
    "            h2 = torch.zeros(1, self.rnn_dims).cuda()\n",
    "            \n",
    "            mels = torch.FloatTensor(mels).cuda().unsqueeze(0)\n",
    "            mels, aux = self.upsample(mels)\n",
    "            \n",
    "            aux_idx = [self.aux_dims * i for i in range(5)]\n",
    "            a1 = aux[:, :, aux_idx[0]:aux_idx[1]]\n",
    "            a2 = aux[:, :, aux_idx[1]:aux_idx[2]]\n",
    "            a3 = aux[:, :, aux_idx[2]:aux_idx[3]]\n",
    "            a4 = aux[:, :, aux_idx[3]:aux_idx[4]]\n",
    "            \n",
    "            seq_len = mels.size(1)\n",
    "            \n",
    "            for i in tqdm(range(seq_len)) :\n",
    "\n",
    "                m_t = mels[:, i, :]\n",
    "                a1_t = a1[:, i, :]\n",
    "                a2_t = a2[:, i, :]\n",
    "                a3_t = a3[:, i, :]\n",
    "                a4_t = a4[:, i, :]\n",
    "                \n",
    "                x = torch.cat([x, m_t, a1_t], dim=1)\n",
    "                x = self.I(x)\n",
    "                h1 = rnn1(x, h1)\n",
    "                \n",
    "                x = x + h1\n",
    "                inp = torch.cat([x, a2_t], dim=1)\n",
    "                h2 = rnn2(inp, h2)\n",
    "                \n",
    "                x = x + h2\n",
    "                x = torch.cat([x, a3_t], dim=1)\n",
    "                x = F.relu(self.fc1(x))\n",
    "                \n",
    "                x = torch.cat([x, a4_t], dim=1)\n",
    "                x = F.relu(self.fc2(x))\n",
    "                x = self.fc3(x)\n",
    "                posterior = F.softmax(x, dim=1).view(-1)\n",
    "                distrib = torch.distributions.Categorical(posterior)\n",
    "                sample = 2 * distrib.sample().float() / (self.n_classes - 1.) - 1.\n",
    "                output.append(sample)\n",
    "                x = torch.FloatTensor([[sample]]).cuda()\n",
    "                if i % 100 == 0 :\n",
    "                    speed = int((i + 1) / (time.time() - start))\n",
    "#                     print(\"{}/{} -- Speed: {} samples/sec\".format(i + 1, seq_len, speed))\n",
    "        output = torch.stack(output).cpu().numpy()\n",
    "#         librosa.output.write_wav(save_path, output, ap.sample_rate)\n",
    "#         self.train()\n",
    "        return output\n",
    "    \n",
    "    def get_gru_cell(self, gru) :\n",
    "        gru_cell = nn.GRUCell(gru.input_size, gru.hidden_size)\n",
    "        gru_cell.weight_hh.data = gru.weight_hh_l0.data\n",
    "        gru_cell.weight_ih.data = gru.weight_ih_l0.data\n",
    "        gru_cell.bias_hh.data = gru.bias_hh_l0.data\n",
    "        gru_cell.bias_ih.data = gru.bias_ih_l0.data\n",
    "        return gru_cell"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Instantiate and Check Upsampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ap.hop_length / 11 / 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "model = Model(rnn_dims=512, fc_dims=512, bits=bits, pad=2,\n",
    "              upsample_factors=(5, 5, 11), feat_dims=80,\n",
    "              compute_dims=128, res_out_dims=128, res_blocks=10).cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists(MODEL_PATH):\n",
    "    torch.save(model.state_dict(), MODEL_PATH) \n",
    "model.load_state_dict(torch.load(MODEL_PATH)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mels, aux = model.preview_upsampling(m.cuda())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_spec(m[0].numpy())\n",
    "plot_spec(mels[0].cpu().detach().numpy().T)\n",
    "plot_spec(aux[0].cpu().detach().numpy().T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "global step\n",
    "step = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists(STEP_PATH):\n",
    "    np.save(STEP_PATH, step)\n",
    "step = np.load(STEP_PATH)\n",
    "step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.NLLLoss().cuda()\n",
    "optimiser = optim.Adam(model.parameters())\n",
    "model.train()\n",
    "def train(model, optimiser, criterion, epochs, batch_size, classes, seq_len, step, lr=1e-4) :\n",
    "    loss_threshold = 4.0\n",
    "    trn_loader = DataLoader(dataset, collate_fn=collate, batch_size=batch_size, \n",
    "                            num_workers=4, shuffle=True, pin_memory=True)\n",
    "    for p in optimiser.param_groups : p['lr'] = lr\n",
    "    for e in range(epochs) :\n",
    "        running_loss = 0.\n",
    "        val_loss = 0.\n",
    "        start = time.time()\n",
    "        running_loss = 0.\n",
    "        iters = len(trn_loader)\n",
    "        for i, (x, m, y) in enumerate(trn_loader) :\n",
    "            x, m, y = x.cuda(), m.cuda(), y.cuda()\n",
    "            y_hat = model(x, m)\n",
    "            y_hat = y_hat.transpose(1, 2).unsqueeze(-1)\n",
    "            y = y.unsqueeze(-1)\n",
    "            loss = criterion(y_hat, y)\n",
    "            optimiser.zero_grad()\n",
    "            loss.backward()\n",
    "            optimiser.step()\n",
    "            running_loss += loss.item()\n",
    "            speed = (i + 1) / (time.time() - start)\n",
    "            avg_loss = running_loss / (i + 1)\n",
    "            step += 1\n",
    "            if step % 10 == 0:\n",
    "                print(\"Epoch: {}/{} -- Batch: {}/{} -- Loss: {:.3f}\"\n",
    "                      \" -- Speed: {:.2f} steps/sec -- Step: {}\"\\\n",
    "                      .format(e + 1, epochs, i + 1, iters, avg_loss, speed, step))\n",
    "        torch.save(model.state_dict(), MODEL_PATH)\n",
    "        np.save(STEP_PATH, step)\n",
    "        print(' <saved>')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# train(model, optimiser, criterion, epochs=1000, batch_size=64, classes=2**bits, \n",
    "#       seq_len=seq_len, step=step, lr=1e-4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate Samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate(samples=3) :\n",
    "    global output\n",
    "    k = step // 1000\n",
    "    test_mels = [np.load(f'{DATA_PATH}mel/{id}.npy') for id in test_ids[:samples]]\n",
    "    ground_truth = [np.load(f'{DATA_PATH}quant/{id}.npy') for id in test_ids[:samples]]\n",
    "    for i, (gt, mel) in enumerate(zip(ground_truth, test_mels)) :\n",
    "        print('\\nGenerating: %i/%i' % (i+1, samples))\n",
    "#         gt = 2 * gt.astype(np.float32) / (2**bits - 1.) - 1.\n",
    "        gt = ap.mulaw_decode(gt, 2**bits)\n",
    "        librosa.output.write_wav(f'{GEN_PATH}{k}k_steps_{i}_target.wav', gt, sr=ap.sample_rate)\n",
    "        output = model.generate(mel)\n",
    "        output = ap.mulaw_decode(output, 2**bits)\n",
    "        librosa.output.write_wav(f'{GEN_PATH}{k}k_steps_{i}_generated.wav', output, sr=ap.sample_rate)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import librosa\n",
    "generate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plot(output)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
